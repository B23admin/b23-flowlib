--- #sample flow description
  processor_group_name: 'DTCC_CDS_DATA'
  description: 'DTCC_CDS_DATA_Specific_Start'
  controllers:
    - name: 'AWS Credential Controller'
      type: 'org.apache.nifi.processors.aws.credentials.provider.service.AWSCredentialsProviderControllerService'
      properties: {}
  processors:
    - name: 'Initialize Start Date'
      type: 'org.apache.nifi.processors.standard.GenerateFlowFile'
      scheduling_strategy: 'TIMER_DRIVEN'
      scheduling_period: '0 sec'
      concurrently_schedulable_task_count: 1
      properties: {'date':"${'1546559239':toDate('MM-dd-YYYY', 'GMT')}"}
      auto_terminate: []
      comments: 'Generates a request every 24 hours at 11:30pm for a downstream HTTP request'
      connections:
        - downstream_name: 'Create DTCC URL'
          relationship: ['success']
          config: {'back_pressure_data_size_threshold': '2 GB'}

    - name: 'Create DTCC URL'
      type: 'org.apache.nifi.processors.attributes.UpdateAttribute'
      scheduling_strategy: 'TIMER_DRIVEN'
      scheduling_period: '0 sec'
      concurrently_schedulable_task_count: 1
      properties:
          'url': 'https://kgc0418-tdw-data2-0.s3.amazonaws.com/slices/CUMULATIVE_CREDITS_${date}.zip'
      auto_terminate: ['Failure', 'No Retry', 'Original', 'Retry']
      comments: 'Creates URL object based on date string'
      connections:
        - downstream_name: 'Get Object via HTTP'
          relationship: ['success']
          config: {'back_pressure_data_size_threshold': '1 GB'}

    - name: 'Get Object via HTTP'
      type: 'org.apache.nifi.processors.standard.InvokeHTTP'
      scheduling_strategy: 'TIMER_DRIVEN'
      scheduling_period: '0 sec'
      concurrently_schedulable_task_count: 1
      properties:
          'HTTP Method': 'GET'
          'Remote URL': '${url}'
      auto_terminate: ['Failure', 'No Retry', 'Original', 'Retry']
      comments: 'Gets an object via HTTP request'
      connections:
        - downstream_name: 'Put Object in S3'
          relationship: ['Response']
          config: {'back_pressure_data_size_threshold': '1 GB'}

    - name: 'Put Object in S3'
      type: 'org.apache.nifi.processors.aws.s3.PutS3Object'
      scheduling_strategy: 'TIMER_DRIVEN'
      scheduling_period: '0 sec'
      concurrently_schedulable_task_count: 1
      properties:
          'Object Key': '${date}.zip'
          'Bucket': 'b23-cftc/dtcc-cd'
      auto_terminate: ['failure']
      comments: 'Puts an object via S3'
      connections:
        - downstream_name: 'Increment Date'
          relationship: ['success']
          config: {'back_pressure_data_size_threshold': '1 GB'}

    - name: 'Increment Date'
      type: 'org.apache.nifi.processors.attributes.UpdateAttribute'
      scheduling_strategy: 'TIMER_DRIVEN'
      scheduling_period: '0 sec'
      concurrently_schedulable_task_count: 1
      properties:
          'date': 'date:plus(86400)'
      auto_terminate: ['Failure', 'No Retry', 'Original', 'Retry']
      comments: 'Increments an attribute timestamp by 24 hours'
      connections:
        - downstream_name: 'Initialize New Date Flow File'
          relationship: ['success']
          config: {'back_pressure_data_size_threshold': '1 GB'}

    - name: 'Initialize New Date Flow File'
      type: 'org.apache.nifi.processors.standard.AttributesToCSV'
      scheduling_strategy: 'TIMER_DRIVEN'
      scheduling_period: '0 sec'
      concurrently_schedulable_task_count: 1
      properties:
          'attribute-list': 'date'
          'destination': 'flowfile-content'
          'include-core-attributes' : 'false'
      auto_terminate: ['failure']
      comments: 'Generates a flow file object with a date that is 24 hours later than the prior'
      connections:
        - downstream_name: 'Create DTCC URL'
          relationship: ['success']
          config: {'back_pressure_data_size_threshold': '1 GB'}